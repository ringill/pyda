{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обязательная часть\n",
    "\n",
    "Вам необходимо написать функцию, которая будет основана на поиске по сайту habr.com. Функция в качестве параметра должна принимать список запросов для поиска (например, ['python', 'анализ данных']) и на основе материалов, попавших в результаты поиска по каждому запросу, возвращать датафрейм вида:\n",
    "\n",
    "<дата> - <заголовок> - <ссылка на материал>\n",
    "В рамках задания предполагается работа только с одной (первой) страницей результатов поисковой выдачи для каждого запроса. Материалы в датафрейме не должны дублироваться, если они попадали в результаты поиска для нескольких запросов из списка.\n",
    "\n",
    "# Дополнительная часть (необязательная)\n",
    "Функция из обязательной части задания должна быть расширена следующим образом:\n",
    "\n",
    "кроме списка ключевых слов для поиска необходимо объявить параметр с количеством страниц поисковой выдачи. Т.е. при передаче в функцию аргумента 4 необходимо получить материалы с первых 4 страниц результатов;\n",
    "в датафрейме должны быть столбцы с полным текстом найденных материалов и количеством лайков:\n",
    "<дата> - <заголовок> - <ссылка на материал> - <текст материала> - <количество лайков>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата</th>\n",
       "      <th>заголовок</th>\n",
       "      <th>ссылка на материал</th>\n",
       "      <th>текст материала</th>\n",
       "      <th>количество лайков</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>В Яндекс.Облаке открыт доступ к анализу данных...</td>\n",
       "      <td>https://habr.com/news/497766</td>\n",
       "      <td>Сегодня на платформе Яндекс.Облако мы открывае...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>В России начался отбор на национальную школьну...</td>\n",
       "      <td>https://habr.com/news/763620</td>\n",
       "      <td>&lt;p&gt;Начался отбор на школьную олимпиаду DANO по...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-17</td>\n",
       "      <td>ИТМО провёл исследование open source в сферах ...</td>\n",
       "      <td>https://habr.com/news/844072</td>\n",
       "      <td>&lt;figure class=\"full-width\"&gt;&lt;img data-blurred=\"...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-10</td>\n",
       "      <td>Центральный университет и AIRI создают лаборат...</td>\n",
       "      <td>https://habr.com/news/865422</td>\n",
       "      <td>&lt;p&gt;Центральный университет вместе с некоммерче...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>3 бесплатные нейросети, которые упрощают анали...</td>\n",
       "      <td>https://habr.com/news/870320</td>\n",
       "      <td>&lt;p&gt;Не люблю громадные подборки сервисов, котор...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>Создание общей архитектуры для высокопроизводи...</td>\n",
       "      <td>https://habr.com/news/539454</td>\n",
       "      <td>Сегодня высокопроизводительные вычисления (&lt;a ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-08-22</td>\n",
       "      <td>ETL в анализе данных без перерывов на кофе и к...</td>\n",
       "      <td>https://habr.com/news/574110</td>\n",
       "      <td>&lt;p&gt;&lt;img data-blurred=\"true\" data-src=\"https://...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>Как понять, что пришло время внедрять платформ...</td>\n",
       "      <td>https://habr.com/news/695622</td>\n",
       "      <td>&lt;p&gt;Эффективные управленческие решения основаны...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         дата                                          заголовок  \\\n",
       "0  2020-04-17  В Яндекс.Облаке открыт доступ к анализу данных...   \n",
       "1  2023-09-26  В России начался отбор на национальную школьну...   \n",
       "2  2024-09-17  ИТМО провёл исследование open source в сферах ...   \n",
       "3  2024-12-10  Центральный университет и AIRI создают лаборат...   \n",
       "4  2024-12-27  3 бесплатные нейросети, которые упрощают анали...   \n",
       "5  2021-01-27  Создание общей архитектуры для высокопроизводи...   \n",
       "6  2021-08-22  ETL в анализе данных без перерывов на кофе и к...   \n",
       "7  2022-10-26  Как понять, что пришло время внедрять платформ...   \n",
       "\n",
       "             ссылка на материал  \\\n",
       "0  https://habr.com/news/497766   \n",
       "1  https://habr.com/news/763620   \n",
       "2  https://habr.com/news/844072   \n",
       "3  https://habr.com/news/865422   \n",
       "4  https://habr.com/news/870320   \n",
       "5  https://habr.com/news/539454   \n",
       "6  https://habr.com/news/574110   \n",
       "7  https://habr.com/news/695622   \n",
       "\n",
       "                                     текст материала  количество лайков  \n",
       "0  Сегодня на платформе Яндекс.Облако мы открывае...                 23  \n",
       "1  <p>Начался отбор на школьную олимпиаду DANO по...                  5  \n",
       "2  <figure class=\"full-width\"><img data-blurred=\"...                 11  \n",
       "3  <p>Центральный университет вместе с некоммерче...                  5  \n",
       "4  <p>Не люблю громадные подборки сервисов, котор...                  5  \n",
       "5  Сегодня высокопроизводительные вычисления (<a ...                 14  \n",
       "6  <p><img data-blurred=\"true\" data-src=\"https://...                  8  \n",
       "7  <p>Эффективные управленческие решения основаны...                  2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "search_url = 'https://habr.com/kek/v2/articles'\n",
    "publication_url = 'https://habr.com/news/'\n",
    "\n",
    "def get_data(query, pages=1):\n",
    "  \"\"\"\n",
    "  Принимает: строку поискового запроса и количество страниц\n",
    "  Возвращает: список словарей, содержащих <дата> - <заголовок> - <ссылка на материал> - <количество лайков>; но не <текст материала>\n",
    "  \"\"\"\n",
    "  rows = []\n",
    "  for page in range(1, pages+1):\n",
    "    links = get_links_by_query(query, page)\n",
    "    rows.extend(links)\n",
    "\n",
    "  # Выкидываем дубляжи (по полю id)\n",
    "  unique_ids = set()\n",
    "  unique_data = []\n",
    "  for item in rows:\n",
    "    if item['id'] not in unique_ids:\n",
    "        unique_data.append(item)\n",
    "        unique_ids.add(item['id'])\n",
    "  \n",
    "  # Добавляем ссылки на страницы\n",
    "  for item in unique_data:\n",
    "    link = f\"https://habr.com/news/{item['id']}\"\n",
    "    item['link'] = link\n",
    "    # получаем заголовок и содержимое публикации\n",
    "    publication_data = get_publication_content(link)\n",
    "    item['content'] = publication_data['content']\n",
    "    item['title'] = publication_data['title']\n",
    "\n",
    "  return unique_data\n",
    "\n",
    "def get_links_by_query(query, page):\n",
    "  \"\"\"\n",
    "  Принимает: строку поискового запроса и номер страниц\n",
    "  Возвращает: Ссылки на страницы, удовлетворяющие результату поиска.\n",
    "  \"\"\"\n",
    "  params = {\n",
    "    'query': query, # текстовый запрос\n",
    "    'page': page, # номер страницы\n",
    "    'perPage': 5 # количество результатов на страницу\n",
    "  }\n",
    "  # Как удобно работать со структурированным JSON, а не лазить по HTML-разметке :)\n",
    "  res = requests.get(search_url, params).json()\n",
    "  # Получаем структурированную информацию о каждой публикации; здесь есть почти всё, что нам нужно (не хватает только содержимого статьи)\n",
    "  publication_refs = res.get('publicationRefs', [])\n",
    "\n",
    "  # Список для хранения результатов\n",
    "  publications = []\n",
    "  # Проход по всем ключам словаря\n",
    "  for value in publication_refs.values():\n",
    "    # Извлечение необходимых данных\n",
    "    id_ = value['id']\n",
    "    time_published = value['timePublished']\n",
    "    score = value['statistics'].get('score', None)  # Используем get для безопасного доступа\n",
    "\n",
    "    # Добавление в результат\n",
    "    publications.append({'id': id_, 'timePublished': time_published, 'score': score})\n",
    "  \n",
    "  return publications\n",
    "\n",
    "def get_publication_content(link):\n",
    "  \"\"\"\n",
    "  Принимает: ссылку на новость\n",
    "  Возвращает: текст новости\n",
    "  \"\"\"\n",
    "  res = requests.get(link)\n",
    "  soup = BeautifulSoup(res.text)\n",
    "\n",
    "  # Находим содержимое статьи\n",
    "  post_content_body = soup.find('div', id='post-content-body')\n",
    "  target_div = post_content_body.find('div', xmlns=\"http://www.w3.org/1999/xhtml\")\n",
    "  content = target_div.decode_contents()\n",
    "\n",
    "  # Находим значение загловока\n",
    "  h1_tag = soup.find('h1', {'data-test-id': 'articleTitle'})\n",
    "  span_tag = h1_tag.find('span')\n",
    "  title = span_tag.decode_contents()\n",
    "\n",
    "  return { 'content': content, 'title': title }\n",
    "\n",
    "def pretty_df(data):\n",
    "  \"\"\"Причесываем результаты для вывода\"\"\"\n",
    "  # Создание DataFrame\n",
    "  df = pd.DataFrame(data) \n",
    "  # Удаление столбца 'id'\n",
    "  df = df.drop(columns=['id'])\n",
    "  # Изменение порядка столбцов\n",
    "  df = df.reindex(columns=['timePublished', 'title', 'link', 'content', 'score'])\n",
    "  # Преобразование столбца в datetime; преобразование в московское время и извлечение только даты\n",
    "  df['timePublished'] = pd.to_datetime(df['timePublished']).dt.tz_convert('Europe/Moscow').dt.date\n",
    "  # Переименование столбцов\n",
    "  df = df.rename(columns={\n",
    "    'timePublished': 'дата',\n",
    "    'title': 'заголовок',\n",
    "    'link': 'ссылка на материал',\n",
    "    'content': 'текст материала',\n",
    "    'score': 'количество лайков'\n",
    "    })\n",
    "  \n",
    "  return df\n",
    "\n",
    "# Пример работы\n",
    "# входящие данные\n",
    "typed_query = ['python', 'анализ данных']\n",
    "# преобразуем список в строку, т.к. habr.com вполне успешно работает с простым перечислением ключевых слов через запятую\n",
    "query = ', '.join(typed_query)\n",
    "# вторым параметром указываем количество страниц (по 5 результатов на страницу)\n",
    "df = pretty_df(get_data(query, 2))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
